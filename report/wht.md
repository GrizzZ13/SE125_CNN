## I. 数据处理

## II. 系统设计

### 1. 模型设计

关于本次大作业的模型设计，从图像分类的任务出发，我们决定选择CNN图像分类算法以及其相关的模型。

首先，我们根据PyTorch的tutorial实现了基础的CNN图像分类算法，设计出了一个具有两个卷积层的卷积神经网络，并对其进行实验。经过一些参数调试之后，我们发现，这个模型不能满足我们的作业要求，虽然这个模型的较为简单，训练用时也非常短，但是这个简单的CNN模型在Cifar-10数据集上训练后进行测试的准确率仅有55%左右。

在此基础上，我们调研了当前学术界较为知名、用途广泛的CNN模型，其中有AlexNet、VGG、ResNet，GoogLeNet等。经过调研和阅读，我们决定在AlexNet的基础上，根据Cifar-10数据集的特征，实现自己的CNN模型。实现自己的模型之后，经过一系列的模型优化和参数调试，最终能够达到大约79%的准确率。这个结果相比于最初的模型已经有了很大的提升，在Cifar-10数据测试集上图像分类的效果很好。

但是，这还是没有达到我们的预期目标，为了使我们的实验结果更进一步，达到更为精确的图像分类效果，我们又转而采用当前学术界和工业界广泛使用的ResNet残差网络模型，经过代码实现，最终在Cifar-10数据测试集上达到（（（）））的结果。这个结果超出我们的预期，完全实现了我们对于此次项目的目标。

下面，我会一一介绍上述提到的各个模型。

#### 1. Shallow CNN

Shallow CNN model是我们最开始尝试的模型，它的网络设计和PyTorch官方的CNN tutorial给出的模型是一致的，输入$32*32*3$的RGB三通道图片，经过两个卷积层、两个池化层、两个非线性激活层，经过Flatten连接到三个全连接层，将最终结果映射到$10*1$的向量进行label的判断，损失函数采用常用的交叉熵，利用随机梯度下降进行参数更新。

这个卷积神经网络只有两个卷积层，卷积核大小分别为$5*5$和$5*5$。这个网络的效果非常差，在$EPOCH=100 \ LR=0.001$的条件下训练出的模型在Cifar-10的准确率只有55%左右。

分析其效果不佳的原因，我认为这个网络只有两个卷积层，且每个卷积层卷积核数量非常少，无法提取到足够的图像信息。而且在Cifar-10数据集本身图像较小的情况下经过两个MaxPool池化层处理，损失了较多图像信息。另外，这个模型没有正则化，容易导致梯度爆炸和梯度消失，导致反向传播和参数更新的效果不佳。

以上都是导致这个模型效果不佳的原因。

![](ShallowCNN.svg)

#### 2. ElexNet : Inspired by AlexNet

在经历了Shallow CNN的失败后，我们从其中总结经验教训，考虑从卷积层数量、池化层位置、正则化等方面入手，设计更加优化的模型，以期得到更好的实验结果。

在查阅了论文和资料后，我们了解了当前学术界和工业界一些主流的CNN算法的实现，例如AlexNet、VGG、ResNet，GoogLeNet等。这些模型都在卷积层、卷积核等很多方面做了优化。在综合评估后，我们决定首先在AlexNet的基础上搭建一个CNN网络。下图是AlexNet的模型结构。

![](AlexNet.png)

在AlexNet的启发下，我们搭建了自己的模型，并将其命名为ElexNet。考虑到Cifar-10数据集图片本身尺寸很小的特点，我们并没有完全按照AlexNet论文的描述实现卷积神经网络，而是根据测试效果，调整了卷积核的大小，使其适应数据集的特点。另外，我们还删除了第一个卷积层Conv1之后的池化层Overlapping Max Pool，原因是Cifar-10数据集尺寸过小，经过池化层处理后会损失很多信息。经过测试，我们还修改了一些对模型结果影响不大的结构，以加快拟合速度。

最终，ElexNet在Cifar-10测试集上的测试准确率为79%，这个效果相比与Shallow CNN有了很大的提升。

![](ElexNet.png)

#### 3. ResNet18



### 2. 训练方法

## III. 实验结果

